{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepForge_Custom_Model_from_scratch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸš€ DeepForge Studio - Custom Model (From Scratch)\n",
        "\n",
        "**Auto-generated Training Notebook**\n",
        "\n",
        "### âš¡ Quick Start:\n",
        "1. **Enable GPU:** `Runtime â†’ Change runtime type â†’ GPU`\n",
        "2. **Run this notebook:** `Runtime â†’ Run all`\n",
        "3. **Set your dataset path** where indicated in the code\n4. Ensure your dataset follows the folder structure: `DATA_DIR/class_name/images...`\n",
        "4. **Download the trained model** using the last cell\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# DeepForge Studio - Exported Training Pipeline\n# Generated: 2025-12-17T10:38:56.358Z\n\nimport os, random\nimport numpy as np\n\ndef set_seed(seed=42):\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    try:\n        import tensorflow as tf\n        tf.random.set_seed(seed)\n    except Exception:\n        pass\n\nset_seed(42)\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\n\n# Model architecture\nmodel = models.Sequential([\n    layers.Conv2D(32, (3, 3), strides=1, padding='valid', activation='relu', input_shape=(224, 224, 3)),\n    layers.Conv2D(32, (3, 3), strides=1, padding='valid', activation='relu'),\n    layers.MaxPooling2D((2, 2), strides=2, padding='valid'),\n    layers.Conv2D(32, (3, 3), strides=1, padding='valid', activation='relu'),\n    layers.Conv2D(32, (3, 3), strides=1, padding='valid', activation='relu'),\n    layers.MaxPooling2D((2, 2), strides=2, padding='valid'),\n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dense(5, activation='softmax')\n])\n\n# Summary\nmodel.summary()\n\n# NOTE: Compilation and training steps are included in the exported training pipeline.\n\n\n# ============================\n# TRAINING PIPELINE (EDIT DATA PATH)\n# ============================\nimport tensorflow as tf\n\n# Expected folder structure:\n# DATA_DIR/\n#   class_a/\n#   class_b/\n#   ...\nDATA_DIR = \"path/to/your/image_dataset\"\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 32\nEPOCHS = 50\n\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n    DATA_DIR,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=42,\n    image_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    label_mode=\"categorical\",\n)\n\nval_ds = tf.keras.utils.image_dataset_from_directory(\n    DATA_DIR,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=42,\n    image_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    label_mode=\"categorical\",\n)\n\nAUTOTUNE = tf.data.AUTOTUNE\ntrain_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n\n# Re-compile using UI-selected hyperparams (overrides template defaults safely)\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"],\n)\n\nhistory = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS)\n\nmodel.save(\"deepforge_model.keras\")\nprint(\"Saved model to deepforge_model.keras\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download the trained model (Google Colab only)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('deepforge_model.keras')\n",
        "except Exception as e:\n",
        "    print('Download is supported in Google Colab only:', e)\n"
      ]
    }
  ]
}