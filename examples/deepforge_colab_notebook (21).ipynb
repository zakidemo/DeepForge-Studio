{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepForge_Training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸš€ DeepForge Studio - AI Model Training Pipeline\\n",
        "\\n",
        "**Auto-generated Training Notebook**\\n",
        "\\n",
        "### âš¡ Quick Start:\\n",
        "1. **Enable GPU:** `Runtime â†’ Change runtime type â†’ GPU`\\n",
        "2. **Run this notebook:** `Runtime â†’ Run all`\\n",
        "3. **Add your data** where indicated in the code\\n",
        "4. **Download your trained model** using the last cell\\n",
        "\\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# DeepForge Studio - Exported Training Pipeline\n# Generated: 2025-12-15T21:34:06.524Z\n\nimport os, random\nimport numpy as np\n\ndef set_seed(seed=42):\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    try:\n        import tensorflow as tf\n        tf.random.set_seed(seed)\n    except Exception:\n        pass\n\nset_seed(42)\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\n\n# Model architecture\nmodel = models.Sequential([\n    layers.Conv2D(32, (3, 3), strides=1, padding='valid', activation='relu', input_shape=(224, 224, 3)),\n    layers.MaxPooling2D((2, 2), strides=2, padding='valid'),\n    layers.Conv2D(32, (3, 3), strides=1, padding='valid', activation='relu'),\n    layers.MaxPooling2D((2, 2), strides=2, padding='valid'),\n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(128, activation='relu'),\n    layers.Dense(10, activation='softmax')\n])\n\n# Compile\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel.summary()\n\n# ============================\n# TRAINING PIPELINE (EDIT DATA PATH)\n# ============================\nimport tensorflow as tf\n\nDATA_DIR = \"path/to/your/image_dataset\"\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 32\nEPOCHS = 50\n\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n    DATA_DIR,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=42,\n    image_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    label_mode=\"categorical\",\n)\n\nval_ds = tf.keras.utils.image_dataset_from_directory(\n    DATA_DIR,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=42,\n    image_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    label_mode=\"categorical\",\n)\n\nAUTOTUNE = tf.data.AUTOTUNE\ntrain_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n\n# Re-compile using UI-selected hyperparams (overrides template defaults safely)\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"],\n)\n\nhistory = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS)\n\nmodel.save(\"deepforge_model.keras\")\nprint(\"Saved model to deepforge_model.keras\")\n"
    }
  ]
}